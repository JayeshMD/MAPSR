{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import schemes as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ec2ced",
   "metadata": {},
   "source": [
    "# Data type and device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c75f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911457af",
   "metadata": {},
   "source": [
    "# Generate signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32db0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 1\n",
    "t_true = torch.linspace(0, 10, 1001)\n",
    "x_true = torch.sin(2 * torch.pi * freq * t_true)\n",
    "\n",
    "fig = plt.figure()\n",
    "axs = fig.add_subplot(1, 1, 1)\n",
    "axs.plot(t_true, x_true)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = t_true[1] - t_true[0]\n",
    "Nc = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633b563",
   "metadata": {},
   "source": [
    "<img src=\"./Figures/Model_1.png\" alt=\"Model Outline\" width=\"1000\" height=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec6a1b1",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a22101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t, xx, w0):\n",
    "    return torch.mm(xx, w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c4fde",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedfc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "τ = torch.tensor([0.2], device=device, dtype=dtype, requires_grad=True)\n",
    "w0 = torch.zeros((2, 2), device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "lr_tau = 1e-4\n",
    "lr_w0 = 1\n",
    "batch_size = 20\n",
    "batch_time = 10  # (x_true)-Nc\n",
    "lr_pow_w0 = torch.linspace(0, -2, 100)\n",
    "lr_pow_tau = torch.linspace(0, -4, 100)\n",
    "\n",
    "loss_arr   = []\n",
    "τ_arr      = []\n",
    "τ_grad_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axs = fig.add_subplot(1, 1, 1)\n",
    "for kk in range(2000):\n",
    "\n",
    "    # lr_w0 = 1e-4 + 1e-1 * torch.tanh(torch.tensor(kk/500))\n",
    "    # lr_tau = 1e-1 * torch.tensor(10).pow(lr_pow_tau[kk//100])\n",
    "    batch_time = 10 + ((kk // 100) * 10);\n",
    "\n",
    "    if kk % 100 == 0:\n",
    "        print('lr_w0=', lr_w0)\n",
    "        print('batch_time=', batch_time)\n",
    "\n",
    "    z_true = sc.interp_linear(t_true,x_true,Nc,τ)\n",
    "\n",
    "    if kk % 100 == 0:\n",
    "        st_id = torch.randint(0, len(z_true) - batch_time, (1,)).item()\n",
    "\n",
    "    id_sel = torch.randint(0, z_true.shape[0] - batch_time, (batch_size,))\n",
    "    z_true_stack = torch.stack([z_true[id_sel + i, :] for i in range(batch_time)], dim=0)\n",
    "    t_true_stack = torch.stack([t_true[id_sel + i] for i in range(batch_time)], dim=0)\n",
    "    # print(z_true_stack.shape)\n",
    "    # print(t_true_stack.shape)\n",
    "\n",
    "    for i in range(0, batch_time):\n",
    "        fun = lambda t, x: model(t, x, w0)\n",
    "        if i == 0:\n",
    "            z_pred = z_true_stack[i, :, :].reshape(1, z_true_stack.shape[1], z_true_stack.shape[2])\n",
    "        else:\n",
    "            z_next = sc.rk4(fun, t_true[i], z_pred[i - 1, :, :], dt)\n",
    "            z_pred = torch.cat([z_pred, z_next.reshape(1, z_true_stack.shape[1], z_true_stack.shape[2])], 0)\n",
    "\n",
    "    # print(\"z_pred.shape=\", z_pred.shape)\n",
    "    # print(\"z_true.shape=\",z_true[0:batch_time,:].shape)\n",
    "    # loss = torch.abs((z_true[0:batch_time,:]-z_pred)).sum() + torch.abs(w0).sum()\n",
    "\n",
    "    # loss = (z_true_stack-z_pred).pow(2).mean() #+ 1e-5* torch.abs(w0).sum()\n",
    "    loss = torch.abs((z_true_stack - z_pred)).mean() + 1e-2 * torch.abs(w0).sum()\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w0_old = w0.detach().numpy()\n",
    "        τ_old = τ.detach().numpy()\n",
    "\n",
    "        # print(τ_old)\n",
    "        τ_arr.append(τ_old)\n",
    "        τ_grad_arr.append(τ.grad.detach().numpy())\n",
    "        # print(w0.grad)\n",
    "        w0 -= lr_w0 * w0.grad\n",
    "        if kk > 300:\n",
    "            τ -= lr_tau * τ.grad * (10 * (kk % 10 == 0) + (kk % 10 != 0))\n",
    "\n",
    "        loss_arr.append(loss.item())\n",
    "        # print(loss.item())\n",
    "        if kk % 10 == 0:\n",
    "            # Visualize\n",
    "            plt.cla()\n",
    "            for p_id in range(batch_size):\n",
    "                axs.plot(t_true_stack.detach().numpy()[:, p_id], z_pred[:, p_id, 0].detach().numpy(), 'ro')\n",
    "                axs.plot(t_true_stack.detach().numpy()[:, p_id], z_pred[:, p_id, 1].detach().numpy(), 'bo')\n",
    "\n",
    "            axs.plot(t_true[0:len(z_true)], z_true[:, 0].detach().numpy(), 'r-')\n",
    "            axs.plot(t_true[0:len(z_true)], z_true[:, 1].detach().numpy(), 'b-')\n",
    "            \n",
    "            plt.show(block=False)\n",
    "\n",
    "            fig.canvas.draw()\n",
    "            plt.pause(0.0001)\n",
    "\n",
    "        if kk % 25 == 0:\n",
    "            print(\"iter=\", kk)\n",
    "            print(\"loss=\", loss.detach().numpy())\n",
    "            print(\"w0=\", w0.detach().numpy())\n",
    "            print(\"tau=\", τ.detach().numpy())\n",
    "\n",
    "        w0.grad = None\n",
    "        τ.grad = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venc_PSR_Tau",
   "language": "python",
   "name": "venc_psr_tau"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
